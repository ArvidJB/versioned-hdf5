{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Growth of File Sizes for Versioned-HDF5 Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For these tests, we have generated `.h5` data files using the `generate_data_deterministic.py` script from the repository, using the standard options ([see details here](#standard))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The path to the generated test files is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/home/melissa/projects/versioned-hdf5/analysis\" # change this as necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "from versioned_hdf5 import VersionedHDF5File\n",
    "from generate_data_deterministic import TestVersionedDatasetPerformance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# auxiliary code to format file sizes \n",
    "def format_size(size):\n",
    "    suffixes = ['B', 'KB', 'MB', 'GB']\n",
    "    i = 0\n",
    "    while size >= 1024 and i < len(suffixes)-1:\n",
    "        size = size/1024\n",
    "        i += 1\n",
    "    return f\"{size:.2f} {suffixes[i]}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test 1: Large fraction changes (sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testname = \"test_large_fraction_changes_sparse\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have tested the following numbers of versions (or transactions):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "num_transactions_1 = [50, 100, 500, 1000, 5000, 7500, 10000, 12000, 15000, 20000, 30000]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modify `num_transactions_1` for the desired tests. **Please keep in mind that file sizes can become very large for large numbers of transactions (above 5000 transactions).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_transactions_1 = [50, 100, 500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tests = []\n",
    "for t in num_transactions_1:\n",
    "    filename = os.path.join(path, f\"{testname}_{t}.h5\")\n",
    "    try:\n",
    "        h5pyfile = h5py.File(filename, 'r')\n",
    "    except:\n",
    "        print(f\"File with {t} transactions not available. Creating new file \")\n",
    "        TestVersionedDatasetPerformance().test_large_fraction_changes_sparse(t)\n",
    "        h5pyfile = h5py.File(filename, 'r')\n",
    "    data = VersionedHDF5File(h5pyfile)\n",
    "    tests.append(dict(num_transactions=t, filename=filename, h5pyfile=h5pyfile, data=data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of versions v. File size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start by analyzing how the `.h5` file sizes grow as the number of versions grows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for test in tests:\n",
    "    test['size'] = os.path.getsize(test['filename'])\n",
    "    test['size_label'] = format_size(test['size'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the array size also grows as the number of versions grows, since each transaction is changing the original arrays by adding, deleting and changing values in the original arrays. In order to compute a (naive) theoretical lower bound on the file size, we'll compute how much space each version should take. Keep in mind there is redundant data as some of it is not changed during the staging of a new version but it is still being stored. In this example, we start with three arrays with 5000 elements (2 integer arrays and one float), and in the end we have the following array sizes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for test in tests:\n",
    "    lengths = []\n",
    "    total_size = 0\n",
    "    for vname in test['data']._versions:\n",
    "        if vname != '__first_version__':\n",
    "            version = test['data'][vname]\n",
    "            group_key = list(version.keys())[0]\n",
    "            lengths.append(len(version[group_key]['val']))\n",
    "            total_size += len(version[group_key]['val'])\n",
    "    test['theoretical_sizes'] = 24*total_size\n",
    "    print(f\"Maximum array size for file with {test['num_transactions']}: {max(lengths)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_large_fraction_changes_sparse = []\n",
    "for test in tests:\n",
    "    test_large_fraction_changes_sparse.append(dict((k, test[k]) for k in ['num_transactions', 'filename', 'size', 'size_label', 'theoretical_sizes']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's show the size information in a graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filesizes_1 = np.array([test['size'] for test in test_large_fraction_changes_sparse])\n",
    "sizelabels_1 = np.array([test['size_label'] for test in test_large_fraction_changes_sparse])\n",
    "tsizes_1 = np.array([test['theoretical_sizes'] for test in test_large_fraction_changes_sparse])\n",
    "\n",
    "fig_large_fraction_changes = plt.figure()\n",
    "plt.plot(num_transactions_1, filesizes_1, '*-', ms=12, color='blue', label=\"Actual file size\")\n",
    "plt.plot(num_transactions_1, tsizes_1, 'o-', ms=5, color='magenta', label=\"Theoretical file size\")\n",
    "plt.xlabel(\"Transactions\")\n",
    "plt.title(\"test_large_fraction_changes_sparse\")\n",
    "plt.legend()\n",
    "plt.yticks(filesizes_1, sizelabels_1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just for the sake of reproducibility, we have pickled the filesizes for larger tests so we can recover them later, since large files give us different behaviour:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"test_large_fraction_changes_sparse_versions.pickle\", \"rb\") as pickle_in:\n",
    "    test_large_fraction_changes_sparse = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting these larger file sizes, we get the following graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_transactions_1 = [50, 100, 500, 1000, 5000, 7500, 10000, 12000, 15000, 20000, 30000]\n",
    "filesizes_1 = np.array([test['size'] for test in test_large_fraction_changes_sparse])\n",
    "sizelabels_1 = np.array([test['size_label'] for test in test_large_fraction_changes_sparse])\n",
    "tsizes_1 = np.array([test['theoretical_sizes'] for test in test_large_fraction_changes_sparse])\n",
    "\n",
    "fig_large_fraction_changes_log = plt.figure(figsize=(10,8))\n",
    "plt.plot(num_transactions_1, filesizes_1, '*-', ms=12, color='blue', label=\"Actual file size\")\n",
    "plt.plot(num_transactions_1, tsizes_1, 'o-', ms=5, color='magenta', label=\"Theoretical file size\")\n",
    "plt.xticks([50, 5000, 10000, 15000, 20000, 30000])\n",
    "plt.xlabel(\"Transactions\")\n",
    "plt.title(\"test_large_fraction_changes_sparse\")\n",
    "plt.legend()\n",
    "plt.yticks(filesizes_1[[0, 5, 7, 8, 9, 10]], sizelabels_1[[0, 5, 7, 8, 9, 10]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that between 7500 transactions and 10000 transactions, there is a cross between the curves and the actual filesizes are **smaller** than the expected file size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changing the view to a logarithmic scale, we have the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_large_fraction_changes_log = plt.figure(figsize=(10,8))\n",
    "plt.loglog(num_transactions_1, filesizes_1, '*-', ms=12, color='blue', label=\"Actual file size\")\n",
    "plt.loglog(num_transactions_1, tsizes_1, 'o-', ms=5, color='magenta', label=\"Theoretical file size\")\n",
    "plt.xticks([50, 5000, 10000, 15000, 20000, 30000])\n",
    "plt.xlabel(\"Transactions\")\n",
    "plt.title(\"test_large_fraction_changes_sparse\")\n",
    "plt.legend()\n",
    "plt.yticks(filesizes_1[[0, 5, 7, 8, 9, 10]], sizelabels_1[[0, 5, 7, 8, 9, 10]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finishing up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for test in tests:\n",
    "    test['h5pyfile'].close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test 2: Mostly appends (sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testname = \"test_mostly_appends_sparse\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this case, we have tested the following number of transactions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "num_transactions_2 = [50, 100, 500, 1000, 2000, 5000]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change `num_transactions_2` as desired:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_transactions_2 = [50, 100, 200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up dictionary with test info\n",
    "tests = []\n",
    "for t in num_transactions_2:\n",
    "    filename = os.path.join(path, f\"{testname}_{t}.h5\")\n",
    "    try:\n",
    "        h5pyfile = h5py.File(filename, 'r')\n",
    "    except:\n",
    "        print(f\"File with {t} transactions not available. Creating new file \")\n",
    "        TestVersionedDatasetPerformance().test_mostly_appends_sparse(t)\n",
    "        h5pyfile = h5py.File(filename, 'r')       \n",
    "    data = VersionedHDF5File(h5pyfile)\n",
    "    tests.append(dict(num_transactions=t, filename=filename, h5pyfile=h5pyfile, data=data))\n",
    "\n",
    "# Computing file sizes\n",
    "for test in tests:\n",
    "    test['size'] = os.path.getsize(test['filename'])\n",
    "    test['size_label'] = format_size(test['size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for test in tests:\n",
    "    lengths = []\n",
    "    total_size = 0\n",
    "    for vname in test['data']._versions:\n",
    "        if vname != '__first_version__':\n",
    "            version = test['data'][vname]\n",
    "            group_key = list(version.keys())[0]\n",
    "            lengths.append(len(version[group_key]['val']))\n",
    "            total_size += len(version[group_key]['val'])\n",
    "    test['theoretical_sizes'] = 24*total_size\n",
    "    print(f\"Maximum array size for file with {test['num_transactions']}: {max(lengths)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mostly_appends_sparse = []\n",
    "for test in tests:\n",
    "    test_mostly_appends_sparse.append(dict((k, test[k]) for k in ['num_transactions', 'filename', 'size', 'size_label', 'theoretical_sizes']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filesizes_2 = np.array([test['size'] for test in test_mostly_appends_sparse])\n",
    "sizelabels_2 = np.array([test['size_label'] for test in test_mostly_appends_sparse])\n",
    "tsizes_2 = np.array([test['theoretical_sizes'] for test in test_mostly_appends_sparse])\n",
    "\n",
    "fig_mostly_appends_sparse = plt.figure()\n",
    "plt.plot(num_transactions_2, filesizes_2, '*-', ms=12, color='blue', label=\"Actual file size\")\n",
    "plt.plot(num_transactions_2, tsizes_2, 'o-', ms=5, color='magenta', label=\"Theoretical file size\")\n",
    "plt.xlabel(\"Transactions\")\n",
    "plt.title(\"test_mostly_appends_sparse\")\n",
    "plt.legend()\n",
    "plt.yticks(filesizes_2, sizelabels_2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we have pickled the results of larger tests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"test_mostly_appends_sparse_versions.pickle\", \"rb\") as pickle_in:\n",
    "    test_mostly_appends_sparse = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For these larger tests, we can see the following graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_transactions_2 = [50, 100, 500, 1000, 2000, 5000]\n",
    "filesizes_2 = np.array([test['size'] for test in test_mostly_appends_sparse])\n",
    "sizelabels_2 = np.array([test['size_label'] for test in test_mostly_appends_sparse])\n",
    "tsizes_2 = np.array([test['theoretical_sizes'] for test in test_mostly_appends_sparse])\n",
    "\n",
    "fig_mostly_appends_sparse = plt.figure()\n",
    "plt.plot(num_transactions_2, filesizes_2, '*-', ms=12, color='blue', label=\"Actual file size\")\n",
    "plt.plot(num_transactions_2, tsizes_2, 'o-', ms=5, color='magenta', label=\"Theoretical file size\")\n",
    "plt.xlabel(\"Transactions\")\n",
    "plt.title(\"test_mostly_appends_sparse\")\n",
    "plt.legend()\n",
    "plt.yticks(filesizes_2[[0, 4, 5]], sizelabels_2[[0, 4, 5]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changing the view to a logarithmic scale, we have the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig_large_fraction_changes_log = plt.figure(figsize=(10,8))\n",
    "plt.loglog(num_transactions_2, filesizes_2, '*-', ms=12, color='blue', label=\"Actual file size\")\n",
    "plt.loglog(num_transactions_2, tsizes_2, 'o-', ms=5, color='magenta', label=\"Theoretical file size\")\n",
    "plt.xlabel(\"Transactions\")\n",
    "plt.title(\"test_mostly_appends_sparse\")\n",
    "plt.legend()\n",
    "plt.yticks(filesizes_2, sizelabels_2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this test, we can see that the cross between the graphs happens earlier; for files of approximately 100 versions or more, versioned-hdf5 files have smaller sizes than expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for test in tests:\n",
    "    test['h5pyfile'].close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test 3: Small fraction changes (sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testname = \"test_small_fraction_changes_sparse\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have tested the following numbers of versions (or transactions):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "num_transactions_3 = [50, 100, 500, 1000, 5000, 7500, 10000, 12000, 15000, 20000, 30000]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once more, in order to run tests locally, adjust `num_transactions_3` as desired:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_transactions_3 = [50, 100, 500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up dictionary with test info\n",
    "tests = []\n",
    "for t in num_transactions_3:\n",
    "    filename = os.path.join(path, f\"{testname}_{t}.h5\")\n",
    "    try:\n",
    "        h5pyfile = h5py.File(filename, 'r')\n",
    "    except:\n",
    "        print(f\"File with {t} transactions not available. Creating new file \")\n",
    "        TestVersionedDatasetPerformance().test_small_fraction_changes_sparse(t)\n",
    "        h5pyfile = h5py.File(filename, 'r')\n",
    "    data = VersionedHDF5File(h5pyfile)\n",
    "    tests.append(dict(num_transactions=t, filename=filename, h5pyfile=h5pyfile, data=data))\n",
    "    \n",
    "# Computing file sizes\n",
    "for test in tests:\n",
    "    test['size'] = os.path.getsize(test['filename'])\n",
    "    test['size_label'] = format_size(test['size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for test in tests:\n",
    "    lengths = []\n",
    "    total_size = 0\n",
    "    for vname in test['data']._versions:\n",
    "        if vname != '__first_version__':\n",
    "            version = test['data'][vname]\n",
    "            group_key = list(version.keys())[0]\n",
    "            lengths.append(len(version[group_key]['val']))\n",
    "            total_size += len(version[group_key]['val'])\n",
    "    test['theoretical_sizes'] = 24*total_size\n",
    "    print(f\"Maximum array size for file with {test['num_transactions']}: {max(lengths)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_small_fraction_changes_sparse = []\n",
    "for test in tests:\n",
    "    test_small_fraction_changes_sparse.append(dict((k, test[k]) for k in ['num_transactions', 'filename', 'size', 'size_label', 'theoretical_sizes']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filesizes_3 = np.array([test['size'] for test in test_small_fraction_changes_sparse])\n",
    "sizelabels_3 = np.array([test['size_label'] for test in test_small_fraction_changes_sparse])\n",
    "tsizes_3 = np.array([test['theoretical_sizes'] for test in test_small_fraction_changes_sparse])\n",
    "\n",
    "fig_small_fraction_changes = plt.figure()\n",
    "plt.plot(num_transactions_3, filesizes_3, '*-', ms=12, color='blue', label=\"Actual file size\")\n",
    "plt.plot(num_transactions_3, tsizes_3, 'o-', ms=5, color='magenta', label=\"Theoretical file size\")\n",
    "plt.xlabel(\"Transactions\")\n",
    "plt.title(\"test_small_fraction_changes_sparse\")\n",
    "plt.legend()\n",
    "plt.yticks(filesizes_3, sizelabels_3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have pickled a larger test set for observing the files behaviour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"test_small_fraction_changes_sparse_versions.pickle\", \"rb\") as pickle_in:\n",
    "    test_small_fraction_changes_sparse = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "num_transactions_3 = [50, 100, 500, 1000, 5000, 7500, 10000, 12000, 15000, 20000, 30000]\n",
    "filesizes_3 = np.array([test['size'] for test in test_small_fraction_changes_sparse])\n",
    "sizelabels_3 = np.array([test['size_label'] for test in test_small_fraction_changes_sparse])\n",
    "tsizes_3 = np.array([test['theoretical_sizes'] for test in test_small_fraction_changes_sparse])\n",
    "\n",
    "fig_small_fraction_changes = plt.figure(figsize=(10,8))\n",
    "plt.plot(num_transactions_3, filesizes_3, '*-', ms=12, color='blue', label=\"Actual file size\")\n",
    "plt.plot(num_transactions_3, tsizes_3, 'o-', ms=5, color='magenta', label=\"Theoretical file size\")\n",
    "plt.xticks([50, 5000, 10000, 15000, 20000, 30000])\n",
    "plt.xlabel(\"Transactions\")\n",
    "plt.title(\"test_small_fraction_changes_sparse\")\n",
    "plt.legend()\n",
    "plt.yticks(filesizes_3[[0, 5, 7, 8, 9, 10]], sizelabels_3[[0, 5, 7, 8, 9, 10]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changing to a logarithmic scale, we have the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_small_fraction_changes = plt.figure(figsize=(10,8))\n",
    "plt.loglog(num_transactions_3, filesizes_3, '*-', ms=12, color='blue', label=\"Actual file size\")\n",
    "plt.loglog(num_transactions_3, tsizes_3, 'o-', ms=5, color='magenta', label=\"Theoretical file size\")\n",
    "plt.xticks([50, 5000, 10000, 15000, 20000, 30000])\n",
    "plt.xlabel(\"Transactions\")\n",
    "plt.title(\"test_small_fraction_changes_sparse\")\n",
    "plt.legend()\n",
    "plt.yticks(filesizes_3[[0, 5, 7, 8, 9, 10]], sizelabels_3[[0, 5, 7, 8, 9, 10]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for test in tests:\n",
    "    test['h5pyfile'].close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test 4: Mostly appends (dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testname = \"test_mostly_appends_dense\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this case, we have tested the following number of transactions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "num_transactions_4 = [50, 100, 500, 1000, 2000, 5000, 10000]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change `num_transactions_4` as desired:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_transactions_4 = [10, 20, 30, 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up dictionary with test info\n",
    "tests = []\n",
    "for t in num_transactions_4:\n",
    "    filename = os.path.join(path, f\"{testname}_{t}.h5\")\n",
    "    try:\n",
    "        h5pyfile = h5py.File(filename, 'r')\n",
    "    except:\n",
    "        print(f\"File with {t} transactions not available. Creating new file \")\n",
    "        TestVersionedDatasetPerformance().test_mostly_appends_dense(t)\n",
    "        h5pyfile = h5py.File(filename, 'r')\n",
    "    data = VersionedHDF5File(h5pyfile)\n",
    "    tests.append(dict(num_transactions=t, filename=filename, h5pyfile=h5pyfile, data=data))\n",
    "\n",
    "# Computing file sizes\n",
    "for test in tests:\n",
    "    test['size'] = os.path.getsize(test['filename'])\n",
    "    test['size_label'] = format_size(test['size'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we compute the theoretical file sizes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for test in tests:\n",
    "    lengths = []\n",
    "    total_size = 0\n",
    "    for vname in test['data']._versions:\n",
    "        if vname != '__first_version__':\n",
    "            version = test['data'][vname]\n",
    "            group_key = list(version.keys())[0]\n",
    "            lengths.append(len(version[group_key]['val']))\n",
    "            total_size += len(version[group_key]['val'])\n",
    "    test['theoretical_sizes'] = 24*total_size\n",
    "    print(f\"Maximum array size for file with {test['num_transactions']}: {max(lengths)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mostly_appends_dense = []\n",
    "for test in tests:\n",
    "    test_mostly_appends_dense.append(dict((k, test[k]) for k in ['num_transactions', 'filename', 'size', 'size_label', 'theoretical_sizes']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filesizes_4 = np.array([test['size'] for test in test_mostly_appends_dense])\n",
    "sizelabels_4 = np.array([test['size_label'] for test in test_mostly_appends_dense])\n",
    "tsizes_4 = np.array([test['theoretical_sizes'] for test in test_mostly_appends_dense])\n",
    "\n",
    "fig_mostly_appends_dense = plt.figure()\n",
    "plt.plot(num_transactions_4, filesizes_4, '*-', ms=12, color='blue', label=\"Actual file size\")\n",
    "plt.plot(num_transactions_4, tsizes_4, 'o-', ms=5, color='magenta', label=\"Theoretical file size\")\n",
    "plt.xlabel(\"Transactions\")\n",
    "plt.title(\"test_mostly_appends_dense\")\n",
    "plt.legend()\n",
    "plt.yticks(filesizes_4[[0, 2, 3]], sizelabels_4[[0, 2, 3]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_mostly_appends_dense_log = plt.figure()\n",
    "plt.loglog(num_transactions_4, filesizes_4, '*-', ms=12, color='blue', label=\"Actual file size\")\n",
    "plt.loglog(num_transactions_4, tsizes_4, 'o-', ms=5, color='magenta', label=\"Theoretical file size\")\n",
    "plt.xlabel(\"Transactions\")\n",
    "plt.title(\"test_mostly_appends_dense\")\n",
    "plt.legend()\n",
    "plt.yticks(filesizes_4[[0, 2, 3]], sizelabels_4[[0, 2, 3]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same kind of behaviour we saw on other tests can be seen, with the graphs crossing (but this time on files with 25 versions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for test in tests:\n",
    "    test['h5pyfile'].close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding each file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each versioned HDF5 file contains 3 datasets per version:\n",
    "- `key0`, an array of `int64`\n",
    "- `key1`, an array of `int64`\n",
    "- `val`, an array of `float64`\n",
    "plus metadata about groups, datasets and versions.\n",
    "\n",
    "This means that each file has  \n",
    "\n",
    "```\n",
    "nversions * 24 * arraysize + metadata\n",
    "```\n",
    "bytes of information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='standard'></a>\n",
    "## Standard parameters\n",
    "\n",
    "- `test_large_fraction_changes_sparse`: \n",
    "    - `num_rows_initial = 5000`\n",
    "    - `num_rows_per_append = 10`\n",
    "    - `num_inserts = 10`\n",
    "    - `num_deletes = 10`\n",
    "    - `num_changes = 1000`\n",
    "- `test_small_fraction_changes_sparse`\n",
    "    - `num_rows_initial = 5000`\n",
    "    - `num_rows_per_append = 10`\n",
    "    - `num_inserts = 10`\n",
    "    - `num_deletes = 10`\n",
    "    - `num_changes = 10`\n",
    "- `test_mostly_appends_sparse`:\n",
    "    - `num_rows_initial = 1000`\n",
    "    - `num_rows_per_append = 1000`\n",
    "    - `num_inserts = 10`\n",
    "    - `num_deletes = 10`\n",
    "    - `num_changes = 10`  \n",
    "- `test_mostly_appends_dense`\n",
    "    - `num_rows_initial_0 = 30`\n",
    "    - `num_rows_initial_1 = 30`\n",
    "    - `num_rows_per_append_0 = 1`\n",
    "    - `num_inserts_0 = 1`\n",
    "    - `num_inserts_1 = 10`\n",
    "    - `num_deletes_0 = 1`\n",
    "    - `num_deletes_1 = 1`\n",
    "    - `num_changes = 10`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
